# n8n-nodes-databricks

This is an n8n community node that provides comprehensive integration with Databricks APIs, including Genie AI, SQL, Unity Catalog, Model Serving, Files, and Vector Search capabilities.

![n8n.io - Workflow Automation](https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-logo.png)

## Features

- ğŸ¤– **Genie AI Assistant**: Start conversations, send messages, and execute SQL queries through Databricks' AI assistant
- ğŸ“‚ **File Operations**: Upload, download, list, and manage files in Databricks volumes (up to 5 GiB)
- ğŸ—„ï¸ **Databricks SQL**: Execute SQL queries and manage statements
- ğŸ“š **Unity Catalog**: Manage catalogs, schemas, tables, and volumes
- ğŸ¤– **Model Serving**: Query AI models and manage endpoints
- ğŸ” **Vector Search**: Perform vector similarity searches

## Prerequisites

You need the following installed on your development machine:

* [git](https://git-scm.com/downloads)
* Node.js and pnpm. Minimum version Node 18. You can find instructions on how to install both using nvm (Node Version Manager) for Linux, Mac, and WSL [here](https://github.com/nvm-sh/nvm). For Windows users, refer to Microsoft's guide to [Install NodeJS on Windows](https://docs.microsoft.com/en-us/windows/dev-environment/javascript/nodejs-on-windows).
* Install n8n with:
  ```
  pnpm install n8n -g
  ```
* A Databricks workspace with a personal access token

## Installation

### For Development

1. Clone this repository:
   ```bash
   git clone https://github.com/<your-org>/n8n-nodes-databricks.git
   cd n8n-nodes-databricks
   ```

2. Install dependencies:
   ```bash
   pnpm install
   ```

3. Build the node:
   ```bash
   pnpm build
   ```

4. Link to your n8n installation:
   ```bash
   npm link
   cd ~/.n8n/custom
   npm link n8n-nodes-databricks
   ```

### From npm (Coming Soon)

```bash
npm install n8n-nodes-databricks
```

## Credentials

To use this node, you need to configure Databricks credentials:

1. **Host**: Your Databricks workspace URL (e.g., `https://adb-1234567890123456.7.azuredatabricks.net`)
2. **Token**: Your Databricks personal access token

To generate a token:
1. Log into your Databricks workspace
2. Go to User Settings â†’ Access Tokens
3. Click "Generate New Token"
4. Copy and save the token securely

## Architecture

### ğŸ“Š Project Structure

```
n8n-nodes-databricks/
â”‚
â”œâ”€â”€ ğŸ¯ Main Node Entry Point
â”‚   â””â”€â”€ nodes/Databricks/Databricks.node.ts
â”‚       â”œâ”€â”€ Class: Databricks (implements INodeType)
â”‚       â”œâ”€â”€ Properties:
â”‚       â”‚   â”œâ”€â”€ displayName: 'Databricks'
â”‚       â”‚   â”œâ”€â”€ version: 1
â”‚       â”‚   â”œâ”€â”€ usableAsTool: true (can be used as an AI agent tool)
â”‚       â”‚   â””â”€â”€ requestDefaults: { baseURL, Authorization }
â”‚       â”‚
â”‚       â”œâ”€â”€ Node Configuration:
â”‚       â”‚   â”œâ”€â”€ Resource selector (dropdown):
â”‚       â”‚   â”‚   â”œâ”€â”€ Genie (AI Assistant)
â”‚       â”‚   â”‚   â”œâ”€â”€ Databricks SQL
â”‚       â”‚   â”‚   â”œâ”€â”€ Unity Catalog
â”‚       â”‚   â”‚   â”œâ”€â”€ Model Serving
â”‚       â”‚   â”‚   â”œâ”€â”€ Files
â”‚       â”‚   â”‚   â””â”€â”€ Vector Search
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ Operations (per resource)
â”‚       â”‚   â””â”€â”€ Parameters (per resource)
â”‚       â”‚
â”‚       â””â”€â”€ Execute Method:
â”‚           â”œâ”€â”€ Process each input item
â”‚           â”œâ”€â”€ Handle special cases (custom logic)
â”‚           â””â”€â”€ Error handling with continueOnFail support
â”‚
â”œâ”€â”€ ğŸ“ Resource Definitions
â”‚   â””â”€â”€ nodes/Databricks/resources/
â”‚       â”œâ”€â”€ index.ts (exports all operations & parameters)
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ¤– genie/
â”‚       â”‚   â”œâ”€â”€ operations.ts
â”‚       â”‚   â”‚   â””â”€â”€ Operations: [6 operations]
â”‚       â”‚   â”‚       â”œâ”€â”€ startConversation
â”‚       â”‚   â”‚       â”œâ”€â”€ createMessage
â”‚       â”‚   â”‚       â”œâ”€â”€ getMessage
â”‚       â”‚   â”‚       â”œâ”€â”€ executeMessageQuery
â”‚       â”‚   â”‚       â”œâ”€â”€ getQueryResults
â”‚       â”‚   â”‚       â””â”€â”€ getSpace
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ parameters.ts
â”‚       â”‚       â””â”€â”€ Parameters: spaceId, conversationId, messageId, etc.
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“‚ files/
â”‚       â”‚   â”œâ”€â”€ operations.ts
â”‚       â”‚   â”‚   â””â”€â”€ Operations: [7 operations]
â”‚       â”‚   â”‚       â”œâ”€â”€ uploadFile (PUT binary data)
â”‚       â”‚   â”‚       â”œâ”€â”€ downloadFile (GET file content)
â”‚       â”‚   â”‚       â”œâ”€â”€ deleteFile (DELETE)
â”‚       â”‚   â”‚       â”œâ”€â”€ getFileInfo (HEAD metadata)
â”‚       â”‚   â”‚       â”œâ”€â”€ listDirectory (GET directory contents)
â”‚       â”‚   â”‚       â”œâ”€â”€ createDirectory (PUT)
â”‚       â”‚   â”‚       â””â”€â”€ deleteDirectory (DELETE)
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ parameters.ts
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ—„ï¸ databricksSql/
â”‚       â”œâ”€â”€ ğŸ“š unityCatalog/
â”‚       â”œâ”€â”€ ğŸ¤– modelServing/
â”‚       â””â”€â”€ ğŸ” vectorSearch/
â”‚
â”œâ”€â”€ ğŸ” Credentials
â”‚   â””â”€â”€ credentials/Databricks.credentials.ts
â”‚       â””â”€â”€ DatabricksCredentials interface:
â”‚           â”œâ”€â”€ host: string (Databricks workspace URL)
â”‚           â””â”€â”€ token: string (Personal access token)
â”‚
â””â”€â”€ ğŸ¨ Assets
    â”œâ”€â”€ databricks.svg (light mode icon)
    â””â”€â”€ databricks.dark.svg (dark mode icon)
```

### ğŸ”„ Execution Flow

```
User Input (n8n workflow)
    â†“
1. User selects RESOURCE (e.g., "Genie")
    â†“
2. User selects OPERATION (e.g., "Start Conversation")
    â†“
3. UI displays relevant PARAMETERS (using displayOptions.show)
    â†“
4. User fills in parameters (spaceId, initialMessage, etc.)
    â†“
5. Execute method is called
    â†“
6. Two execution paths:
    â”‚
    â”œâ”€â†’ Path A: Declarative Routing (most operations)
    â”‚   â”œâ”€â”€ n8n uses 'routing' config from operations.ts
    â”‚   â”œâ”€â”€ Automatically builds HTTP request
    â”‚   â”œâ”€â”€ Substitutes parameters using {{$parameter.xxx}}
    â”‚   â””â”€â”€ Sends request with credentials from requestDefaults
    â”‚
    â””â”€â†’ Path B: Custom Logic (special cases)
        â”œâ”€â”€ Files.uploadFile â†’ Custom binary data handling
        â””â”€â”€ Genie operations â†’ Custom switch statement
            â”œâ”€â”€ Build URL dynamically
            â”œâ”€â”€ Create request body
            â”œâ”€â”€ Call this.helpers.httpRequest()
            â””â”€â”€ Return response
    â†“
7. Return INodeExecutionData[][]
```

### ğŸ§© Key Architectural Patterns

#### 1. Resource-Based Organization
Each Databricks API category is a separate "resource" with its own operations and parameters.

#### 2. Declarative Routing
Most operations use n8n's declarative `routing` configuration:
```typescript
routing: {
  request: {
    method: 'POST',
    url: '=/api/2.0/genie/spaces/{{$parameter.spaceId}}/conversations',
    body: {
      initial_message: '={{$parameter.initialMessage}}'
    }
  }
}
```

#### 3. Conditional Parameter Display
Parameters appear/hide based on selected resource and operation:
```typescript
displayOptions: {
  show: {
    resource: ['genie'],
    operation: ['startConversation']
  }
}
```

#### 4. Two Execution Modes
- **Declarative**: n8n handles HTTP requests automatically (most operations)
- **Imperative**: Custom logic in execute() method (files upload, genie operations)

#### 5. Error Handling
Comprehensive error handling with three types:
- **API Errors**: Status code + error details
- **Network Errors**: Connection failures
- **Other Errors**: General exceptions

All support `continueOnFail` mode for resilient workflows.

## Development

### Building the Node

```bash
pnpm build
```

### Linting

```bash
pnpm lint
# or auto-fix
pnpm lintfix
```

### Testing

```bash
pnpm test
```

## Usage Examples

### Example 1: Start a Genie Conversation

1. Add the Databricks node to your workflow
2. Select Resource: **Genie**
3. Select Operation: **Start Conversation**
4. Enter your **Space ID**
5. Enter your **Initial Message**: "Show me sales data for last quarter"

### Example 2: Upload a File to Databricks Volume

1. Add the Databricks node after a node that provides binary data
2. Select Resource: **Files**
3. Select Operation: **Upload File**
4. Configure:
   - Data Field Name: `data`
   - Catalog: `main`
   - Schema: `default`
   - Volume: `my_volume`
   - Path: `reports/report.pdf`

### Example 3: Query Vector Search

1. Add the Databricks node to your workflow
2. Select Resource: **Vector Search**
3. Select Operation: **Query Index**
4. Configure your query parameters

## Adding New Operations

To extend this node with new operations:

1. Navigate to the appropriate resource folder in `nodes/Databricks/resources/`
2. Add the new operation to `operations.ts`:
   ```typescript
   {
     name: 'My New Operation',
     value: 'myNewOperation',
     description: 'Description of what it does',
     action: 'Perform my new operation',
     routing: {
       request: {
         method: 'GET',
         url: '=/api/2.0/path/{{$parameter.id}}'
       }
     }
   }
   ```
3. Add required parameters to `parameters.ts`
4. Rebuild and test

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Support

For issues, questions, or contributions, please visit the [GitHub repository](https://github.com/<your-org>/n8n-nodes-databricks).

## Resources

- [n8n Documentation](https://docs.n8n.io/)
- [Databricks API Documentation](https://docs.databricks.com/api/)
- [n8n Community](https://community.n8n.io/)

## License

[MIT](LICENSE.md)
